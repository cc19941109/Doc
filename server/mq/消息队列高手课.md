# 消息队列

## 1.为什么需要消息队列

1. 消息队列可以解决哪些问题
  - 异步处理，快速返回
  - 流量控制，如何解决秒杀时并发过大的问题
  - 令牌桶用在哪里？怎么使用它进行流量控制
  - 服务解耦
  - 消息订阅发布
2. 消息队列的局限性
  - 延迟问题
  - 复杂度
  - 数据不一致

## 2.如何选择消息队列

### 选择消息队列的基本标准
  - 开源
  - 集成和兼容性
  - 消息不可丢失
  - 集群
  - 性能

### 常见的消息队列

#### RabbitMq

轻量快捷，容易部署，灵活的路由配置，兼容性好

每秒几万到十几万

吞吐量比 RocketMq 差了一个数量级，语言小众，修改源码成本高

#### RocketMq

不错的性能，金融级稳定性，可靠性，响应时延低，可以做在线业务，中文文档多

每秒几十万

周边生态集成和兼容略逊一筹

#### Kafka

Kafka的周边生态是最好的，性能也是最好的

每秒几十万，比rocketMq好，但没有数量级上的差异

时延相对来说比较高(因为批量发送的缘故)

####  Pulsar

存储与设计分离，处于成长期

## 3. 队列和主题的区别


## 4. 消息队列中的事务


消息队列中的“事务”，主要解决的是消息生产者和消息消费者的数据一致性问题。


消息队列中的“事务”，主要解决的是消息生产者和消息消费者的数据一致性问题。

##  5. 如何做到不丢消息

1. 从生产，存储，消费3个方面谈谈如何做到消息不丢失
  - 生产的要处理好发送消息异常的情况，并重发消息
  - 在单机存储时，每个消息都要落盘，在集群配置下，需要将消息发送至2个副本以上，再给客户端回复确认收到
  - 消费时，应当在业务处理完后，再发送消费成功的响应，需要注意的是消费端容易收到重复消息，需要做幂等处理


## 8 答疑

### 网关如何接收服务端的秒杀结果

Mutex


### 单个队列实现并行消费




### 如何保证消息的严格顺序


使用key，一致性hash，可以保证相同key是有序的

只要是满足单调性的分片算法，我们就可以按照“先扩容分区 -> 将旧分区中的遗留消息消费完 -> 同时消费所有分区”这样一个方式，确保扩容过程中消息的严格顺序。

## 9. 如何学习源码 

1. 文档 项目灵魂论文
2. 以点带面读源码，带着问题读源码


## 10. 异步设计提升系统性能

举个例子，为什么同步实现有性能瓶颈？(例如:转账)

用异步的方法，为什么能提升性能

## 11. 网络传输

## 12. 序列化与反序列化

考虑的方面

1. 数据可读性
2. 实现复杂度
3. 性能
4. 信息密度

序列化和反序列化是一个标准，让相同信息能够跨平台跨语言

## 13. 传输协议

1. 断句问题
  - 分隔符
  - 预置长度
2. 全双工问题
  - 使用序号保证顺序
  - 单工通讯的性能远远不如双工通讯的性能

Todo: 服务端和客户端 通信交互100万次
参考  14.5 加餐

##  14. 内存管理

1. 为什么高并发下程序会卡死
  - 垃圾回收繁忙
2. 高并发下如何降低gc的频率与stw时间
  - 对象池  todo
  - 大内存服务器
  - 大对象传递，而不是新建


如果我们的微服务的需求是处理大量的文本，比如说，每次请求会传入一个 10KB 左右的文本，在高并发的情况下，你会如何来优化这个程序，来尽量避免由于垃圾回收导致的进程卡死问题？

1. 增大eden代大小，防止对象晋升到老年代
2. 如果对象大小比较接近，可以考虑池化
3. 大文本对象传递处理，减少大对象的新建

## 14.5 加餐:JMQ异步处理消息

Todo 总结

1. 异步设计，将刷盘和复制分离到异步处理
2. 写缓存将写磁盘操作转为了写内存
3. 几乎无锁
4. 回复响应也做成异步


## 15. Kafka 如何实现高性能IO

1. 批量消息处理
2. 磁盘顺序读写
3. PageCache
  - 通俗地说，PageCache 就是操作系统在内存中给磁盘上的文件建立的缓存。
  - PageCache 读取数据的两种情况
  - Kafka 在读写消息文件的时候，充分利用了 PageCache 的特性。一般来说，消息刚刚写入到服务端就会被消费，按照 LRU 的“优先清除最近最少使用的页”这种策略，读取的时候，对于这种刚刚写入的 PageCache，命中的几率会非常高。
4. ZeroCopy
  - 一种操作系统特性
  - 解释下零拷贝的应用场景
5. DMA是什么？有什么用
  - 优点是速度快，直接内存操作


### 零拷贝

首先，从文件中找到消息数据，读到内存中；
然后，把消息通过网络发给客户端。

这个过程中，数据实际上做了 2 次或者 3 次复制：

1. 从文件复制数据到 PageCache 中，如果命中 PageCache，这一步可以省掉；从 PageCache 复制到应用程序的内存空间中，也就是我们可以操作的对象所在的内存；
2. 从应用程序的内存空间复制到 Socket 的缓冲区，这个过程就是我们调用网络应用框架的 API 发送数据的过程。

Kafka 使用零拷贝技术直接从 PageCache 中把数据复制到 Socket 缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复制，不需要 CPU 参与，速度更快。

如果遇到这种从文件读出数据后再通过网络发送出去的场景，并且这个过程中你不需要对这些数据进行处理，那一定要使用这个零拷贝的方法，可以有效地提升性能。

```c
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

## 16. 缓存策略

按照读写性质，可以分为读写缓存和只读缓存，读写缓存实现起来非常复杂，并且只在消息队列等少数情况下适用。只读缓存适用的范围更广，实现起来也更简单。

这里面有三种方法，第一种是在更新数据的同时去更新缓存，第二种是定期来更新全部缓存，第三种是给缓存中的每个数据设置一个有效期，让它自然过期以达到更新的目的。

对于缓存的置换策略，最优的策略一定是你根据业务来设计的定制化的置换策略，当然你也可以考虑 LRU 这样通用的缓存置换算法。

Todo: LRU
Mysql bufferpool的设计，按比例分young old区

实现LRU置换算法

## 17. 如何使用锁保护共享数据，协调异步线程

1. Java中的读写锁怎么使用？如何实现的？
2. 能不能自己在 Java 中实现一个 try-with-lock 呢？
  - closeable 接口
  - 注解
  - 动态代理，静态代理






## 18. 使用硬件同步原语实现锁

CAS  FAA


## 19. 数据压缩

压缩它的本质是资源的置换，是一个时间换空间，或者说是 CPU 资源换存储资源的游戏。


简单地说，Kafka 的压缩和解压都是在客户端完成的。


### 20. RocketMQ Producer 消息生产的实现过程

1. 门面模式是怎么做的? 有什么优点?
2. 状态模式是什么? 有什么优点?
3. rocketmq producer 如何使用同一套api进行同步/异步发送?

### 21.

### 25. 事务

RocketMQ 中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且，RocketMQ 增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。

而 Kafka 中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功，要么都失败。注意，这里面的多条消息不一定要在同一个主题和分区中，可以是发往多个主题和分区的消息。当然，你可以在 Kafka 的事务执行过程中，加入本地事务，来实现和 RocketMQ 中事务类似的效果，但是 Kafka 是没有事务反查机制的。

### 

### 

### 

### 
